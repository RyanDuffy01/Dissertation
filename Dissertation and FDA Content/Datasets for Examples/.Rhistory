predict(rf)
split_data <- creditmodel::train_test_split(cleaned_data,prop=0.4,seed=190005680)
test_data <- split_data$test
mean_price <- mean(split_data$test$price)
model_1 <- lm(price~.,split_data$train)
model_1 <- lm(price~.,split_data$train)
model_1_predicted <- predict(model_1,newdata = split_data$test)
model_1_residuals <- split_data$test$price - model_1_predicted
MSE <- sum((split_data$test$price-mean_price)^2)
SSE <- sum(model_1_residuals^2)
model_1_RMSE <- sqrt((1/length(model_1_residuals))*SSE)
model_1_R_Square <- 1-SSE/MSE
model_1_R_Square
model_2_predicted <- predict(rf,newdata=test_data_rf)
split_rf_data <- creditmodel::train_test_split(random_forest_data,prop=0.4,seed=190005680)
train_data_rf <- split_rf_data$train
test_data_rf <- split_rf_data$test
model_2_predicted <- predict(rf,newdata=test_data_rf)
model_2_residuals <- split_data$test$price - model_2_predicted
model_2_residuals <- split_rf_data$test$price - model_2_predicted
MSE <- sum((split_rf_data$test$price-mean_price)^2)
SSE <- sum(model_2_residuals^2)
model_1_RMSE <- sqrt((1/length(model_2_residuals))*SSE)
MSE_model_2 <- sum((split_rf_data$test$price-mean_price)^2)
SSE_model_2 <- sum(model_2_residuals^2)
model_2_RMSE <- sqrt((1/length(model_2_residuals))*SSE)
model_2_R_Square <- 1-SSE_model_2/MSE_model_2
model_2_R_Square
model_3 <- rpart(
formula = price ~ .,
data    = train_data,
method  = "anova"
)
library(rpart)
model_3 <- rpart(
formula = price ~ .,
data    = train_data,
method  = "anova"
)
predict(model_3)
model_3_predicted <- predict(model_3,newdata=test_data)
model_3_residuals <- test_data$price - model_3_predicted
model_3_predicted <- predict(model_3,newdata=test_data)
model_3_residuals <- test_data$price - model_3_predicted
MSE_model_3 <- sum((test_data$price-mean_price)^2)
SSE_model_3 <- sum(model_3_residuals^2)
model_3_RMSE <- sqrt((1/length(model_3_residuals))*SSE)
model_3_R_Square <- 1-SSE_model_3/MSE_model_3
model_3_R_Square
rpart.plot::rpart.plot(model_3)
paste("Model",1:3)
data.frame(
Model=paste("Model",1:3),
RMSE=c(model_1_RMSE,model_2_RMSE,model_3_RMSE),
`R Squared`= c(model_1_R_Square,model_2_R_Square,model_3_R_Square)
)
model_1 <- lm(price~.,split_data$train)
# finds the prices model 1 predicts for the cars in the testing dataset
model_1_predicted <- predict(model_1,newdata = split_data$test)
# find the difference between the predicted and actual prices of the cars in the testing dataset
model_1_residuals <- split_data$test$price - model_1_predicted
# finds the sum of squared differences between prices of cars and the mean
MSE_model_1 <- sum((split_data$test$price-mean_price)^2)
# finds the sum of squared differences between the predicted and actual prices of cars
SSE_model_1 <- sum(model_1_residuals^2)
# finds the root mean squared error of the model based in the testing dataset
model_1_RMSE <- sqrt((1/length(model_1_residuals))*SSE_model_1)
# finds the R Squared Value of the testing dataset
model_1_R_Square <- 1-SSE_model_1/MSE_model_2
# must rename columns with numbers as start values
random_forest_data <- cleaned_data %>%
rename("Five_Speed"=`5_Speed_Automatic`,"Six_Speed"=`6_Speed_Automatic`,"Eight_Speed"=`8_Speed_Automatic`)
# splits data with new column names in same way as original data was split
split_rf_data <- creditmodel::train_test_split(random_forest_data,prop=0.4,seed=190005680)
train_data_rf <- split_rf_data$train
test_data_rf <- split_rf_data$test
# fits random forest model with all coefficients
model_2 <- randomForest(
price ~ .,
data=split_rf_data$train
)
model_2_predicted <- predict(rf,newdata=test_data_rf)
model_2_residuals <- split_rf_data$test$price - model_2_predicted
MSE_model_2 <- sum((split_rf_data$test$price-mean_price)^2)
SSE_model_2 <- sum(model_2_residuals^2)
model_2_RMSE <- sqrt((1/length(model_2_residuals))*SSE_model_2)
model_2_R_Square <- 1-SSE_model_2/MSE_model_2
model_2_predicted <- predict(rf,newdata=test_data_rf)
mod
model_2_predicted <- predict(model_2,newdata=test_data_rf)
model_2_predicted <- predict(model_2,newdata=test_data_rf)
model_2_residuals <- split_rf_data$test$price - model_2_predicted
MSE_model_2 <- sum((split_rf_data$test$price-mean_price)^2)
SSE_model_2 <- sum(model_2_residuals^2)
model_2_RMSE <- sqrt((1/length(model_2_residuals))*SSE_model_2)
model_2_R_Square <- 1-SSE_model_2/MSE_model_2
# Fits regression tree model with all coefficients
model_3 <- rpart(
formula = price ~ .,
data    = train_data,
method  = "anova"
)
model_3_predicted <- predict(model_3,newdata=test_data)
model_3_residuals <- test_data$price - model_3_predicted
MSE_model_3 <- sum((test_data$price-mean_price)^2)
SSE_model_3 <- sum(model_3_residuals^2)
model_3_RMSE <- sqrt((1/length(model_3_residuals))*SSE_model_3)
model_3_R_Square <- 1-SSE_model_3/MSE_model_3
data.frame(
Model=paste("Model",1:3),
RMSE=c(model_1_RMSE,model_2_RMSE,model_3_RMSE),
`R Squared`= c(model_1_R_Square,model_2_R_Square,model_3_R_Square)
)
# finds the prices model 1 predicts for the cars in the testing dataset
model_1_predicted <- predict(model_1,newdata = split_data$test)
# find the difference between the predicted and actual prices of the cars in the testing dataset
model_1_residuals <- split_data$test$price - model_1_predicted
# finds the sum of squared differences between prices of cars and the mean
ME_model_1 <- sum((split_data$test$price-mean_price)^2)
# finds the sum of squared differences between the predicted and actual prices of cars
SSE_model_1 <- sum(model_1_residuals^2)
# finds the root mean squared error of the model based in the testing dataset
model_1_RMSE <- sqrt((1/length(model_1_residuals))*SSE_model_1)
# finds the R Squared Value of the testing dataset
model_1_R_Square <- 1-SSE_model_1/ME_model_1
model_2_predicted <- predict(model_2,newdata=test_data_rf)
model_3_predicted <- predict(model_3,newdata=test_data)
ME_model_3 <- sum((test_data$price-mean_price)^2)
SSE_model_3 <- sum(model_3_residuals^2)
model_3_RMSE <- sqrt((1/length(model_3_residuals))*SSE_model_3)
data.frame(
Model=paste("Model",1:3),
RMSE=c(model_1_RMSE,model_2_RMSE,model_3_RMSE),
`R Squared`= c(model_1_R_Square,model_2_R_Square,model_3_R_Square)
)
varImpPlot(model_2)
varImpPlot(model_2)
varImpPlot(model_2,title="Random Forets Model")
varImpPlot(model_2,title="Random Forest Model")
varImpPlot(model_2,main="Random Forest Model")
varImpPlot(model_2,main="Random Forest Model")
library(fda)
library(tidyverse)
setwd("~/Dissertation/Dissertation and FDA Content/Datasets for Examples")
mortality_rates_wide <- read_csv("Alcohol Mortality Rates Per Country.csv", skip = 6)
mortality_rates_long <- pivot_longer(mortality_rates_wide,values_to="MortalityRate",cols=2:5,names_to = "Country")
ggplot(mortality_rates_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_point()+
ylab("Age-standardised death rates per 100,000 people")
Years <- unique(mortality_rates_long$Year)
basis_mortality_rates <- create.bspline.basis(range(Years),
breaks=Years,
norder=4)
observation_matrix <- data.matrix(mortality_rates_wide[,c(-1)])
GCV_func <- function(log_lambda,basis,observations,time_points,penalty){
lambda <- 10^log_lambda
fd_par_obj <- fdPar(basis,penalty,lambda)
smoothbasisobj <- smooth.basis(time_points,observations,fd_par_obj)
return(sum(smoothbasisobj$gcv))
}
optimised_function <- optimise(GCV_func,lower=0,upper=10,basis=basis_mortality_rates,observations=observation_matrix,time_points=Years,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis_mortality_rates,2,minimum_lambda)
sample_of_functions <- smooth.basis(Years,observation_matrix,fd_par_obj)$fd
sample_of_functions$fdnames$time <- Years
sample_of_functions$fdnames$values <- "Mortality Rate"
year_mesh <- seq(2001,2020,0.01)
eval_df <- as.data.frame(eval.fd(year_mesh,sample_of_functions)) %>%
mutate(Year=year_mesh)
eval_df_long <- pivot_longer(eval_df,names_to = "Country",values_to = "MortalityRate",cols=1:4)
par(mfrow=c(1,1))
ggplot(eval_df_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_line()+
geom_point(data=mortality_rates_long,aes(x=Year,y=MortalityRate,col=Country),inherit.aes = FALSE,alpha=0.2)+
ylab("Age-standardised death rates per 100,000 people")
ggplot(mortality_rates_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_point()+
ylab("Age-standardised death rates per 100,000 people")
ggplot(eval_df_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_line()+
geom_point(data=mortality_rates_long,aes(x=Year,y=MortalityRate,col=Country),inherit.aes = FALSE,alpha=0.2)+
ylab("Age-standardised death rates per 100,000 people")
shap_test <- function(vector){
shapiro.test(vector)$p.value
}
residuals_matrix <- eval.fd(Years,sample_of_functions)-observation_matrix
apply(t(residuals_matrix),1,shap_test)
#gives visualisation of the mean of this sample
mean_func <- mean.fd(sample_of_functions)
mean_plot_df <- data.frame(Year=year_mesh,mean=eval.fd(mean_func,year_mesh))
ggplot(eval_df_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_line()+
geom_point(data=mortality_rates_long,aes(x=Year,y=MortalityRate,col=Country),inherit.aes = FALSE,alpha=0.2)+
geom_line(data=mean_plot_df,aes(x=Year,y=mean),inherit.aes = FALSE) +
ylab("Age-standardised death rates per 100,000 people")
#gives standard deviation of this sample
sd_func <- sd.fd(sample_of_functions)
sd_plot_df <- data.frame(Year=year_mesh,stand_dev=eval.fd(sd_func,year_mesh))
ggplot(sd_plot_df,aes(x=Year,y=stand_dev)) +
geom_line() +
ylab("Standard Deviation in Curves")
principle_components_of_sample <- pca.fd(sample_of_functions)
func_eval <- eval.fd(year_mesh,principle_components_of_sample$harmonics)
PC_DF <- data.frame(
Year = year_mesh,
PC_1 = func_eval[,1],
PC_2 = func_eval[,2]
)
ggplot(PC_DF,aes(x=Year,y=PC_1))+
geom_line() +
ylab("Principal Component Function 1")
ggplot(PC_DF,aes(x=Year,y=PC_2))+
geom_line()
scores_df <- data.frame(
PC_1 = principle_components_of_sample$scores[,1],
PC_2 = principle_components_of_sample$scores[,2],
Country=colnames(observation_matrix)
)
ggplot(scores_df,aes(x=PC_1,y=PC_2,label=Country))+
geom_point()+
geom_text(hjust = 0, nudge_x = 1)+
xlim(c(-25,45)) +
xlab("Score of Principle Component 1") +
ylab("Score of Principle Component 2")
derivs <- deriv.fd(sample_of_functions,Lfdobj = 1)
eval_df_derivs <- as.data.frame(eval.fd(year_mesh,derivs)) %>%
mutate(Year=year_mesh)
eval_df_derivs_long <- pivot_longer(eval_df_derivs,names_to = "Country",values_to = "MortalityRate",cols=1:4)
ggplot(eval_df_derivs_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_line()+
ylab("Change in Age-standardised death rates per 100,000 people")
principle_components_of_derivs <- pca.fd(derivs)
func_eval_derivs <- eval.fd(year_mesh,principle_components_of_derivs$harmonics)
PC_DF_derivs <- data.frame(
Year = year_mesh,
PC_1 = func_eval_derivs[,1],
PC_2 = func_eval_derivs[,2]
)
ggplot(PC_DF_derivs,aes(x=Year,y=PC_1))+
geom_line() +
ylab("Principal Component Function 1")
ggplot(PC_DF_derivs,aes(x=Year,y=PC_2))+
geom_line()
scores_df_derivs <- data.frame(
PC_1 = principle_components_of_sample$scores[,1],
PC_2 = principle_components_of_sample$scores[,2],
Country=colnames(observation_matrix)
)
ggplot(scores_df_derivs,aes(x=PC_1,y=PC_2,label=Country))+
geom_point()+
geom_text(hjust = 0, nudge_x = 1)+
xlim(c(-25,45)) +
xlab("Score of Principle Component 1") +
ylab("Score of Principle Component 2")
fit_individ_func <- function(time_points,obs_matrix,basis){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim <- rep_dims[i]
data_SALSA <- data.frame(
response=obs_matrix[,i],
x_axis=x_axis
)
optimise(GCV_func,lower=0,upper=10,basis=basis,observations=observation_matrix,time_points=time_points,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis,2,minimum_lambda)
smoothbasisobj <- smooth.basis(time_points,observation_matrix,fd_par_obj)
#### COMPLETE THIS ####
#merged_coefs <- cbind(fd1$coefs, fd2$coefs)
#merged_fd <- fd(coef = merged_coefs, basisobj = minutebasis)
#is.fd(merged_fd)
}
}
sample_of_functions
fit_individ_func <- function(time_points,obs_matrix,basis){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim <- rep_dims[i]
data_SALSA <- data.frame(
response=obs_matrix[,i],
x_axis=x_axis
)
optimise(GCV_func,lower=0,upper=10,basis=basis,observations=observation_matrix,time_points=time_points,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis,2,minimum_lambda)
fd_obj <- smooth.basis(time_points,observation_matrix,fd_par_obj)$fd
if (i==1){
coefs <- fd_obj$coefs
} else{
coefs <- cbind(coefs, fd_obj$coefs)
}
}
merged_fd <- fd(coef = coefs, basisobj =basis)
return(is.fd(merged_fd))
}
fit_individ_func(Years,observation_matrix,basis_mortality_rates)
fit_individ_func <- function(time_points,obs_matrix,basis){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim <- rep_dims[i]
optimised_function <- optimise(GCV_func,lower=0,upper=10,basis=basis,observations=observation_matrix,time_points=time_points,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis,2,minimum_lambda)
fd_obj <- smooth.basis(time_points,observation_matrix,fd_par_obj)$fd
if (i==1){
coefs <- fd_obj$coefs
} else{
coefs <- cbind(coefs, fd_obj$coefs)
}
}
merged_fd <- fd(coef = coefs, basisobj =basis)
return(is.fd(merged_fd))
}
fit_individ_func(Years,observation_matrix,basis_mortality_rates)
fit_individ_func <- function(time_points,obs_matrix,basis){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim <- rep_dims[i]
optimised_function <- optimise(GCV_func,lower=0,upper=10,basis=basis,observations=observation_matrix,time_points=time_points,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis,2,minimum_lambda)
fd_obj <- smooth.basis(time_points,observation_matrix,fd_par_obj)$fd
if (i==1){
coefs <- fd_obj$coefs
} else{
coefs <- cbind(coefs, fd_obj$coefs)
}
}
merged_fd <- fd(coef = coefs, basisobj =basis)
return(merged_fd)
}
fit_individ_func(Years,observation_matrix,basis_mortality_rates)
fit_individ_func <- function(time_points,obs_matrix,basis){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim <- rep_dims[i]
optimised_function <- optimise(GCV_func,lower=0,upper=10,basis=basis,observations=observation_matrix[,i],time_points=time_points,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis,2,minimum_lambda)
fd_obj <- smooth.basis(time_points,observation_matrix,fd_par_obj)$fd
if (i==1){
coefs <- fd_obj$coefs
} else{
coefs <- cbind(coefs, fd_obj$coefs)
}
}
merged_fd <- fd(coef = coefs, basisobj =basis)
return(merged_fd)
}
fit_individ_func(Years,observation_matrix,basis_mortality_rates)
fit_individ_func <- function(time_points,obs_matrix,basis){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim <- rep_dims[i]
optimised_function <- optimise(GCV_func,lower=0,upper=10,basis=basis,observations=observation_matrix[,i],time_points=time_points,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis,2,minimum_lambda)
fd_obj <- smooth.basis(time_points,observation_matrix[,i],fd_par_obj)$fd
if (i==1){
coefs <- fd_obj$coefs
} else{
coefs <- cbind(coefs, fd_obj$coefs)
}
}
merged_fd <- fd(coef = coefs, basisobj =basis)
return(merged_fd)
}
fit_individ_func(Years,observation_matrix,basis_mortality_rates)
fit_individ_func <- function(time_points,obs_matrix,basis){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim_i <- rep_dims[i]
optimised_function <- optimise(GCV_func,lower=0,upper=10,basis=basis,observations=observation_matrix[,i],time_points=time_points,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis,2,minimum_lambda)
fd_obj <- smooth.basis(time_points,observation_matrix[,i],fd_par_obj)$fd
coefs_i <- fd_obj$coefs
colnames(coefs_i) <- dim_i
if (i==1){
coefs <- coefs_i
} else{
coefs <- cbind(coefs, coefs_i)
}
}
merged_fd <- fd(coef = coefs, basisobj =basis)
return(merged_fd)
}
fit_individ_func(Years,observation_matrix,basis_mortality_rates)
fit_individ_func <- function(time_points,obs_matrix,basis){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim_i <- rep_dims[i]
optimised_function <- optimise(GCV_func,lower=0,upper=10,basis=basis,observations=observation_matrix[,i],time_points=time_points,penalty=2)
minimum_log_lambda <- optimised_function$minimum
minimum_lambda <- 10^minimum_log_lambda
fd_par_obj <- fdPar(basis,2,minimum_lambda)
fd_obj <- smooth.basis(time_points,observation_matrix[,i],fd_par_obj)$fd
coefs_i <- fd_obj$coefs
colnames(coefs_i) <- dim_i
if (i==1){
coefs <- coefs_i
} else{
coefs <- cbind(coefs, coefs_i)
}
}
merged_fd <- fd(coef = coefs, basisobj =basis)
merged_fd$fdnames$reps <- rep_dims
return(merged_fd)
}
fit_individ_func(Years,observation_matrix,basis_mortality_rates)
ind_fit_funcs <- fit_individ_func(Years,observation_matrix,basis_mortality_rates)
ind_fit_funcs <- fit_individ_func(Years,observation_matrix,basis_mortality_rates)
eval_df_indv <- as.data.frame(eval.fd(year_mesh,ind_fit_funcs)) %>%
mutate(Year=year_mesh)
eval_df_indv_long <- pivot_longer(eval_df_indv,names_to = "Country",values_to = "MortalityRate",cols=1:4)
ggplot(mortality_rates_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_point()+
ylab("Age-standardised death rates per 100,000 people")
ggplot(eval_df_indv_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_line()+
geom_point(data=mortality_rates_long,aes(x=Year,y=MortalityRate,col=Country),inherit.aes = FALSE,alpha=0.2)+
ylab("Age-standardised death rates per 100,000 people")
ggplot(eval_df_long,aes(x=Year,y=MortalityRate,col=Country))+
geom_line()+
geom_point(data=mortality_rates_long,aes(x=Year,y=MortalityRate,col=Country),inherit.aes = FALSE,alpha=0.2)+
ylab("Age-standardised death rates per 100,000 people")
residuals_matrix <- eval.fd(Years,ind_fit_funcs)-observation_matrix
apply(t(residuals_matrix),1,shap_test)
loglambda <- seq(-6,6,0.25)
list_of_gcvs <- c()
list_of_dfs <- c()
for (log_lam in loglambda){
lambda <- 10^log_lam
fd_par_obj <- fdPar(basis_mortality_rates,2,lambda)
smoothbasisobj <- smooth.basis(Years,as.matrix(mortality_rates_wide[,c(-1)]),fd_par_obj)
list_of_gcvs <- c(list_of_gcvs,sum(smoothbasisobj$gcv))
list_of_dfs <- c(list_of_dfs,fd_par_obj$df)
}
log_lambda_df <- data.frame(
loglambda=loglambda,
lambda=10^loglambda,
GCV=list_of_gcvs
)
ggplot(log_lambda_df,aes(x=loglambda,y=GCV)) +
geom_point() +
geom_line()+
geom_vline(xintercept = minimum_log_lambda)
colnames(observation_matrix)
observation_matrix[1,]
SALSA_Fit_fda <- function(x_axis,obs_matrix,start_knots,min_knots,max_knots,degree,maxIter,gaps){
rep_dims <-  colnames(obs_matrix)
for (i in 1:ncol(obs_matrix)){
dim <- rep_dims[i]
data_SALSA <- data.frame(
response=obs_matrix[,i],
x_axis=x_axis
)
initialModel <- glm(response ~ -1, data=data_SALSA,family="Gaussian")
varList <- c("x_axis")
SALSA1DList <- list(fitnessMeasure="BIC",
minKnots_1d=min_knots, maxKnots_1d=max_knots,
startKnots_1d=start_knots, degree=degree,
maxIterations=maxIter, gaps=gaps)
# Run SALSA
SALSA <- MRSea::runSALSA1D(initialModel=initialModel,
salsa1dlist=SALSA1DList,
varlist=varList,
factorlist=NULL,
datain=data_SALSA,
splineParams=NULL,
suppress.printout=TRUE)
SALSA_Fit <- SALSA$bestModel
internal_knots <- SALSA_Fit$splineParams[[2]]$knots
knots <- append(x_axis[1],internal_knots)
knots <- append(knots,x_axis[length(x_axis)])
#smoothing_parameter <-
basis <- create.bspline.basis(range(x_axis),
breaks=knots,
norder=degree+1)
#fd_par_obj <- fdPar(basis,2,smoothing_parameter)
#smoothbasisobj <- smooth.basis(x_axis,obs_matrix,fd_par_obj)
#### COMPLETE THIS ####
#merged_coefs <- cbind(fd1$coefs, fd2$coefs)
#merged_fd <- fd(coef = merged_coefs, basisobj = minutebasis)
#is.fd(merged_fd)
}
return(initialModel)
}
edit(getAnywhere('runSALSA1DFit'), file='source_rfcv.r')
edit(MRSea::runSALSA1D)
observation_matrix
SALSA_Fit_fda(Years,
observation_matrix,
1,
1,
30,
3,
30,
0)
apply(t(residuals_matrix),1,shapiro.test)
shap_test <- function(vector){
shapiro.test(vector)$p.value
}
residuals_matrix <- eval.fd(Years,sample_of_functions)-observation_matrix
apply(t(residuals_matrix),1,shap_test)
